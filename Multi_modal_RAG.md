以上内容翻译成中文如下：

### 概要

我们使用了一个多模态检索模型（基于CLIP）来从一组图像中检索与用户查询最相似的图像。然后，我们使用一个基于Vicuna的链式模型来生成一个回答，该回答基于检索到的图像的内容。

### 检索

1. 检索模型首先根据查询中的文本内容从图像中检索最相似的图像。
2. 然后，我们使用检索到的图像的文本摘要来生成一个回答。

### 示例

用户查询：“请提供有关MongoDB, Cloudflare和Datadog的财务指标信息。”

1. 检索模型找到了一个包含这些公司财务指标的表格图像。
2. 然后，我们使用这个图像的文本摘要来生成一个回答，其中包含了MongoDB, Cloudflare和Datadog的EV/NTM Rev和NTM Rev Growth等财务指标。

### RAG

现在让我们运行RAG并测试生成回答的能力。

```python
# 运行RAG链
chain_multimodal_rag.invoke(query)
```

### 考虑因素

**检索**

* 检索是基于图像摘要和文本块的相似性进行的。
* 这需要一些仔细的考虑，因为图像检索可能会因为存在竞争的文本块而失败。
* 为了解决这个问题，我生成了更大的（4k标记）文本块，并为检索对其进行摘要。

**图像大小**

* 合成回答的质量似乎对图像大小敏感，正如预期的那样。
* 我将很快进行评估以更仔细地测试这一点。